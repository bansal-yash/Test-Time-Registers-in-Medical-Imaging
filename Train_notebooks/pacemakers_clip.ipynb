{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d700f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:25:38.967631Z",
     "iopub.status.busy": "2025-11-21T16:25:38.967328Z",
     "iopub.status.idle": "2025-11-21T16:25:52.090174Z",
     "shell.execute_reply": "2025-11-21T16:25:52.089493Z"
    },
    "papermill": {
     "duration": 13.132956,
     "end_time": "2025-11-21T16:25:52.091609",
     "exception": false,
     "start_time": "2025-11-21T16:25:38.958653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cp -r /kaggle/input/test-time-registers-code/* /kaggle/working/\n",
    "! pip -qqq install ftfy\n",
    "\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "src = \"/kaggle/working/clip/clip/vocab/bpe_simple_vocab_16e6.txt\"\n",
    "dst = \"/kaggle/working/clip/clip/vocab/bpe_simple_vocab_16e6.txt.gz\"\n",
    "with open(src, \"rb\") as f_in:\n",
    "    with gzip.open(dst, \"wb\") as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "import json\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3134470f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:25:52.106321Z",
     "iopub.status.busy": "2025-11-21T16:25:52.105972Z",
     "iopub.status.idle": "2025-11-21T16:25:52.114347Z",
     "shell.execute_reply": "2025-11-21T16:25:52.113810Z"
    },
    "papermill": {
     "duration": 0.016608,
     "end_time": "2025-11-21T16:25:52.115342",
     "exception": false,
     "start_time": "2025-11-21T16:25:52.098734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def load_images(orthonet_path, count=10, images_only=True):\n",
    "#     # Load the CSV file\n",
    "#     csv_path = os.path.join(orthonet_path, 'train.csv')\n",
    "#     df = pd.read_csv(csv_path)\n",
    "    \n",
    "#     # Get the image filenames (not mask files)\n",
    "#     image_filenames = df['filenames'].tolist()\n",
    "    \n",
    "#     # Sample random images\n",
    "#     if count > len(image_filenames):\n",
    "#         sampled_filenames = image_filenames\n",
    "#     else:\n",
    "#         sampled_filenames = random.sample(image_filenames, count)\n",
    "    \n",
    "#     # Construct full paths and load images\n",
    "#     # Images are in orthonet_path/orthonet data/orthonet data/\n",
    "#     images_dir = os.path.join(orthonet_path, 'orthonet data', 'orthonet data')\n",
    "    \n",
    "#     image_files = []\n",
    "#     sampled_paths = []\n",
    "#     for filename in sampled_filenames:\n",
    "#         full_path = os.path.join(images_dir, filename)\n",
    "#         image_files.append(Image.open(full_path))\n",
    "#         sampled_paths.append(full_path)\n",
    "    \n",
    "#     print(\"Loaded {} images\".format(len(image_files)))\n",
    "    \n",
    "#     if images_only:\n",
    "#         return image_files\n",
    "#     else:\n",
    "#         return image_files, sampled_paths\n",
    "\n",
    "def load_images(pacemaker_path, count=10, images_only=True, split='Train'):\n",
    "    \"\"\"\n",
    "    Load images from Pacemaker dataset.\n",
    "    \n",
    "    Args:\n",
    "        pacemaker_path: Root path to pacemaker dataset\n",
    "        count: Number of images to sample\n",
    "        images_only: If True, return only images; if False, return (images, paths, labels)\n",
    "        split: 'train' or 'test'\n",
    "    \n",
    "    Returns:\n",
    "        If images_only: list of PIL Images\n",
    "        Otherwise: (list of PIL Images, list of paths, list of class labels)\n",
    "    \"\"\"\n",
    "    split_path = os.path.join(pacemaker_path, split)\n",
    "    \n",
    "    # Get all class folders\n",
    "    all_classes = [d for d in os.listdir(split_path) \n",
    "                   if os.path.isdir(os.path.join(split_path, d))]\n",
    "    \n",
    "    print(f\"Found {len(all_classes)} classes in {split} split\")\n",
    "    \n",
    "    # Collect all image paths with their class labels\n",
    "    all_image_paths = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for class_name in all_classes:\n",
    "        class_path = os.path.join(split_path, class_name)\n",
    "        \n",
    "        # Get all image files in this class folder\n",
    "        image_files = [f for f in os.listdir(class_path) \n",
    "                      if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
    "        \n",
    "        for img_file in image_files:\n",
    "            all_image_paths.append(os.path.join(class_path, img_file))\n",
    "            all_labels.append(class_name)\n",
    "    \n",
    "    print(f\"Found {len(all_image_paths)} total images\")\n",
    "    \n",
    "    # Sample images\n",
    "    if count > len(all_image_paths):\n",
    "        sampled_indices = list(range(len(all_image_paths)))\n",
    "    else:\n",
    "        sampled_indices = random.sample(range(len(all_image_paths)), count)\n",
    "    \n",
    "    # Load sampled images\n",
    "    image_files = []\n",
    "    sampled_paths = []\n",
    "    \n",
    "    for idx in sampled_indices:\n",
    "        img_path = all_image_paths[idx]\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            image_files.append(img)\n",
    "            sampled_paths.append(img_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "    \n",
    "    print(f\"Successfully loaded {len(image_files)} images\")\n",
    "    \n",
    "    if images_only:\n",
    "        return image_files\n",
    "    else:\n",
    "        return image_files, sampled_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c9e499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:25:52.128953Z",
     "iopub.status.busy": "2025-11-21T16:25:52.128765Z",
     "iopub.status.idle": "2025-11-21T16:25:52.159023Z",
     "shell.execute_reply": "2025-11-21T16:25:52.158266Z"
    },
    "papermill": {
     "duration": 0.038471,
     "end_time": "2025-11-21T16:25:52.160199",
     "exception": false,
     "start_time": "2025-11-21T16:25:52.121728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from shared import utils\n",
    "utils.load_images = load_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816cef9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-21T16:25:52.174590Z",
     "iopub.status.busy": "2025-11-21T16:25:52.174059Z",
     "iopub.status.idle": "2025-11-21T16:25:52.194916Z",
     "shell.execute_reply": "2025-11-21T16:25:52.194299Z"
    },
    "papermill": {
     "duration": 0.029323,
     "end_time": "2025-11-21T16:25:52.195985",
     "exception": false,
     "start_time": "2025-11-21T16:25:52.166662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from shared.utils import (\n",
    "    load_images,\n",
    "    plot_images_with_max_per_row,\n",
    "    plot_attn_maps,\n",
    "    filter_layers,\n",
    ")\n",
    "from shared.algorithms import find_register_neurons\n",
    "import yaml\n",
    "\n",
    "sys.path.append(\"clip/\")\n",
    "sys.path.append(\"dinov2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f0b094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:25:52.209650Z",
     "iopub.status.busy": "2025-11-21T16:25:52.209451Z",
     "iopub.status.idle": "2025-11-21T16:25:52.212508Z",
     "shell.execute_reply": "2025-11-21T16:25:52.211933Z"
    },
    "papermill": {
     "duration": 0.011231,
     "end_time": "2025-11-21T16:25:52.213573",
     "exception": false,
     "start_time": "2025-11-21T16:25:52.202342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = \"clip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a788f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:25:52.226887Z",
     "iopub.status.busy": "2025-11-21T16:25:52.226693Z",
     "iopub.status.idle": "2025-11-21T16:26:07.240731Z",
     "shell.execute_reply": "2025-11-21T16:26:07.240055Z"
    },
    "papermill": {
     "duration": 15.022288,
     "end_time": "2025-11-21T16:26:07.242108",
     "exception": false,
     "start_time": "2025-11-21T16:25:52.219820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL == \"dinov2\":\n",
    "    from dinov2_state import load_dinov2_state\n",
    "\n",
    "    config = {\n",
    "        \"backbone_size\": \"vitl14\",\n",
    "        \"device\": \"cuda:0\",\n",
    "        \"detect_outliers_layer\": -2,\n",
    "        \"register_norm_threshold\": 150,\n",
    "        \"highest_layer\": 19,\n",
    "        \"top_k\": 50,\n",
    "    }\n",
    "\n",
    "    state = load_dinov2_state(config)\n",
    "    \n",
    "elif MODEL == \"clip\":\n",
    "    from clip_state import load_clip_state\n",
    "\n",
    "    config = {\n",
    "        \"model_name\": \"ViT-B-16\",\n",
    "        \"pretrained\": \"laion2b_s34b_b88k\",\n",
    "        \"device\": \"cuda\",\n",
    "        \"highest_layer\": 5,\n",
    "        \"detect_outliers_layer\": -1,\n",
    "        \"register_norm_threshold\": 30,\n",
    "        \"top_k\": 20,\n",
    "    }\n",
    "\n",
    "    state = load_clip_state(config)\n",
    "else:\n",
    "    raise ValueError(f\"Model {MODEL} not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30fa029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:26:07.257003Z",
     "iopub.status.busy": "2025-11-21T16:26:07.256758Z",
     "iopub.status.idle": "2025-11-21T16:26:07.260957Z",
     "shell.execute_reply": "2025-11-21T16:26:07.260355Z"
    },
    "papermill": {
     "duration": 0.012745,
     "end_time": "2025-11-21T16:26:07.262065",
     "exception": false,
     "start_time": "2025-11-21T16:26:07.249320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"/kaggle/input/pacemakers\"\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "run_model = state[\"run_model\"]\n",
    "model = state[\"model\"]\n",
    "preprocess = state[\"preprocess\"]\n",
    "hook_manager = state[\"hook_manager\"]\n",
    "num_layers = state[\"num_layers\"]\n",
    "num_heads = state[\"num_heads\"]\n",
    "patch_size = state[\"patch_size\"]\n",
    "config = state[\"config\"]\n",
    "patch_height = IMAGE_SIZE // patch_size\n",
    "patch_width = IMAGE_SIZE // patch_size\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e9f2c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:26:07.275983Z",
     "iopub.status.busy": "2025-11-21T16:26:07.275748Z",
     "iopub.status.idle": "2025-11-21T16:26:07.690323Z",
     "shell.execute_reply": "2025-11-21T16:26:07.689546Z"
    },
    "papermill": {
     "duration": 0.422814,
     "end_time": "2025-11-21T16:26:07.691478",
     "exception": false,
     "start_time": "2025-11-21T16:26:07.268664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = load_images(IMAGE_PATH, count=2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f0fe83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:26:07.706796Z",
     "iopub.status.busy": "2025-11-21T16:26:07.706540Z",
     "iopub.status.idle": "2025-11-21T16:26:08.391623Z",
     "shell.execute_reply": "2025-11-21T16:26:08.390920Z"
    },
    "papermill": {
     "duration": 0.694172,
     "end_time": "2025-11-21T16:26:08.392988",
     "exception": false,
     "start_time": "2025-11-21T16:26:07.698816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_image = preprocess(image).unsqueeze(0).to(device)\n",
    "hook_manager.reinit()\n",
    "hook_manager.finalize()\n",
    "representation = run_model(model, processed_image)\n",
    "\n",
    "attention_maps = hook_manager.get_attention_maps()  # shape (L, H, N, N)\n",
    "layer_outputs = hook_manager.get_layer_outputs()  # shape (L, N, D)\n",
    "\n",
    "patch_norms = np.linalg.norm(layer_outputs[:, 1:], axis=2).reshape(\n",
    "    num_layers, patch_height, patch_width\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6479d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:26:08.407839Z",
     "iopub.status.busy": "2025-11-21T16:26:08.407578Z",
     "iopub.status.idle": "2025-11-21T16:26:08.580097Z",
     "shell.execute_reply": "2025-11-21T16:26:08.579344Z"
    },
    "papermill": {
     "duration": 0.181412,
     "end_time": "2025-11-21T16:26:08.581326",
     "exception": false,
     "start_time": "2025-11-21T16:26:08.399914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Input\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e414992",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:26:08.600385Z",
     "iopub.status.busy": "2025-11-21T16:26:08.600124Z",
     "iopub.status.idle": "2025-11-21T16:26:10.369915Z",
     "shell.execute_reply": "2025-11-21T16:26:10.369107Z"
    },
    "papermill": {
     "duration": 1.780862,
     "end_time": "2025-11-21T16:26:10.371415",
     "exception": false,
     "start_time": "2025-11-21T16:26:08.590553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot patch norms across all layers. Notice that outliers appear in the later layers.\n",
    "\n",
    "plt = plot_images_with_max_per_row(patch_norms, max_per_row=4, image_title=\"Layer\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc2162c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:26:10.391256Z",
     "iopub.status.busy": "2025-11-21T16:26:10.391029Z",
     "iopub.status.idle": "2025-11-21T16:26:16.178324Z",
     "shell.execute_reply": "2025-11-21T16:26:16.177587Z"
    },
    "papermill": {
     "duration": 5.801656,
     "end_time": "2025-11-21T16:26:16.182870",
     "exception": false,
     "start_time": "2025-11-21T16:26:10.381214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot attention maps\n",
    "\n",
    "cls_attn_maps = attention_maps[:, :, 0, 1:].reshape(\n",
    "    num_layers, num_heads, patch_height, patch_width\n",
    ")\n",
    "plt = plot_attn_maps(cls_attn_maps)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94648d4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:26:16.212972Z",
     "iopub.status.busy": "2025-11-21T16:26:16.212720Z",
     "iopub.status.idle": "2025-11-21T16:26:16.832408Z",
     "shell.execute_reply": "2025-11-21T16:26:16.831496Z"
    },
    "papermill": {
     "duration": 0.635976,
     "end_time": "2025-11-21T16:26:16.833575",
     "exception": false,
     "start_time": "2025-11-21T16:26:16.197599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rand_images = load_images(IMAGE_PATH, count=10)\n",
    "max_patch_norms = [0] * num_layers\n",
    "max_attn_norms = [0] * num_layers\n",
    "\n",
    "for image in tqdm(rand_images, desc=\"Processing images\"):\n",
    "    processed_image = preprocess(image).unsqueeze(0).to(device)\n",
    "    hook_manager.reinit()\n",
    "    hook_manager.finalize()\n",
    "    representation = run_model(model, processed_image)\n",
    "    attention_maps = hook_manager.get_attention_maps()  # shape (L, H, N, N)\n",
    "    layer_outputs = hook_manager.get_layer_outputs()  # shape (L, N, D)\n",
    "\n",
    "    patch_norms = np.max(\n",
    "        np.linalg.norm(layer_outputs[:, 1 : patch_height * patch_width + 1], axis=2),\n",
    "        axis=1,\n",
    "    )\n",
    "    attn_norms = np.max(\n",
    "        np.mean(attention_maps[:, :, 0, 1 : patch_height * patch_width + 1], axis=1),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    for j in range(num_layers):\n",
    "        max_attn_norms[j] += attn_norms[j]\n",
    "        max_patch_norms[j] += patch_norms[j]\n",
    "\n",
    "max_attn_norms = [x / len(rand_images) for x in max_attn_norms]\n",
    "max_patch_norms = [x / len(rand_images) for x in max_patch_norms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a0ac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:26:16.862123Z",
     "iopub.status.busy": "2025-11-21T16:26:16.861875Z",
     "iopub.status.idle": "2025-11-21T16:26:17.209496Z",
     "shell.execute_reply": "2025-11-21T16:26:17.208697Z"
    },
    "papermill": {
     "duration": 0.363746,
     "end_time": "2025-11-21T16:26:17.210997",
     "exception": false,
     "start_time": "2025-11-21T16:26:16.847251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 5), dpi=100)\n",
    "\n",
    "# === Subplot 1: Patch Norms ===\n",
    "ax1.plot(\n",
    "    range(num_layers),\n",
    "    max_patch_norms,\n",
    "    marker=\"o\",\n",
    "    markersize=8,\n",
    "    color=\"steelblue\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax1.set_title(\"Average Max Patch Norms (Layer output)\")\n",
    "ax1.set_xlabel(\"Layer\")\n",
    "ax1.set_ylabel(\"Norm\")\n",
    "ax1.set_xticks(range(0, num_layers, 2))  # Show every second tick\n",
    "ax1.tick_params(axis=\"both\")\n",
    "ax1.tick_params(axis=\"x\", which=\"major\", pad=15)\n",
    "ax1.margins(x=0.1)\n",
    "ax1.grid(True, linestyle=\"-\")\n",
    "\n",
    "# === Subplot 2: Attention Norms ===\n",
    "ax2.plot(\n",
    "    range(num_layers),\n",
    "    max_attn_norms,\n",
    "    marker=\"^\",\n",
    "    markersize=8,\n",
    "    color=\"orange\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax2.set_title(\"Average Max Attention (CLS)\")\n",
    "ax2.set_xlabel(\"Layer\")\n",
    "ax2.set_ylabel(\"Attention Value\")\n",
    "ax2.set_xticks(range(0, num_layers, 2))  # Show every second tick\n",
    "ax2.tick_params(axis=\"both\")\n",
    "ax2.tick_params(axis=\"x\", which=\"major\", pad=15)\n",
    "ax2.margins(x=0.1)\n",
    "ax2.grid(True, linestyle=\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7739fd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:26:17.241531Z",
     "iopub.status.busy": "2025-11-21T16:26:17.241262Z",
     "iopub.status.idle": "2025-11-21T16:26:17.245596Z",
     "shell.execute_reply": "2025-11-21T16:26:17.244825Z"
    },
    "papermill": {
     "duration": 0.021171,
     "end_time": "2025-11-21T16:26:17.246674",
     "exception": false,
     "start_time": "2025-11-21T16:26:17.225503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "#              PARAMETERS               #\n",
    "#########################################\n",
    "\n",
    "# layer used to detect outliers based on the patch norms. Set to the last layer (-1) for CLIP and second-to-last layer (-2) for DINOv2 large\n",
    "detect_outliers_layer = config[\"detect_outliers_layer\"]\n",
    "register_norm_threshold = config[\n",
    "    \"register_norm_threshold\"\n",
    "]  # threshold for detecting register neurons\n",
    "\n",
    "print(detect_outliers_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdafb097",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:26:17.276944Z",
     "iopub.status.busy": "2025-11-21T16:26:17.276472Z",
     "iopub.status.idle": "2025-11-21T16:27:27.667131Z",
     "shell.execute_reply": "2025-11-21T16:27:27.666127Z"
    },
    "papermill": {
     "duration": 70.40763,
     "end_time": "2025-11-21T16:27:27.669105",
     "exception": false,
     "start_time": "2025-11-21T16:26:17.261475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "register_neurons = find_register_neurons(\n",
    "    model_state=state,\n",
    "    image_path=IMAGE_PATH,\n",
    "    detect_outliers_layer=detect_outliers_layer,\n",
    "    processed_image_cnt=1000,\n",
    "    device=\"cuda\",\n",
    "    register_norm_threshold=register_norm_threshold,\n",
    "    apply_sparsity_filter=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6f820d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:27:27.739748Z",
     "iopub.status.busy": "2025-11-21T16:27:27.738993Z",
     "iopub.status.idle": "2025-11-21T16:27:27.796348Z",
     "shell.execute_reply": "2025-11-21T16:27:27.795744Z"
    },
    "papermill": {
     "duration": 0.093111,
     "end_time": "2025-11-21T16:27:27.797566",
     "exception": false,
     "start_time": "2025-11-21T16:27:27.704455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(register_neurons, \"register_neurons.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae0e47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:27:27.865778Z",
     "iopub.status.busy": "2025-11-21T16:27:27.865090Z",
     "iopub.status.idle": "2025-11-21T16:27:28.059971Z",
     "shell.execute_reply": "2025-11-21T16:27:28.059307Z"
    },
    "papermill": {
     "duration": 0.230252,
     "end_time": "2025-11-21T16:27:28.061353",
     "exception": false,
     "start_time": "2025-11-21T16:27:27.831101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "register_neurons = torch.load(\"register_neurons.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba24bd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:27:28.129219Z",
     "iopub.status.busy": "2025-11-21T16:27:28.128961Z",
     "iopub.status.idle": "2025-11-21T16:27:28.133052Z",
     "shell.execute_reply": "2025-11-21T16:27:28.132143Z"
    },
    "papermill": {
     "duration": 0.039292,
     "end_time": "2025-11-21T16:27:28.134120",
     "exception": false,
     "start_time": "2025-11-21T16:27:28.094828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "#              PARAMETERS               #\n",
    "#########################################\n",
    "top_k = config[\"top_k\"]\n",
    "highest_layer = config[\"highest_layer\"]\n",
    "num_registers = 1\n",
    "\n",
    "print(highest_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d442641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:27:28.201637Z",
     "iopub.status.busy": "2025-11-21T16:27:28.201096Z",
     "iopub.status.idle": "2025-11-21T16:27:28.208462Z",
     "shell.execute_reply": "2025-11-21T16:27:28.207617Z"
    },
    "papermill": {
     "duration": 0.042516,
     "end_time": "2025-11-21T16:27:28.209675",
     "exception": false,
     "start_time": "2025-11-21T16:27:28.167159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_register_neurons = filter_layers(register_neurons, highest_layer=highest_layer)\n",
    "\n",
    "neurons_to_ablate = dict()\n",
    "for layer, neuron, score in filtered_register_neurons[:top_k]:\n",
    "    if layer not in neurons_to_ablate:\n",
    "        neurons_to_ablate[layer] = []\n",
    "    neurons_to_ablate[layer].append(neuron)\n",
    "print(neurons_to_ablate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c069c894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:27:28.277494Z",
     "iopub.status.busy": "2025-11-21T16:27:28.277004Z",
     "iopub.status.idle": "2025-11-21T16:27:31.568015Z",
     "shell.execute_reply": "2025-11-21T16:27:31.567229Z"
    },
    "papermill": {
     "duration": 3.3265,
     "end_time": "2025-11-21T16:27:31.569276",
     "exception": false,
     "start_time": "2025-11-21T16:27:28.242776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_images = load_images(IMAGE_PATH, count=50)\n",
    "image_norms = []\n",
    "register_norms = []\n",
    "image_attentions = []\n",
    "register_attentions = []\n",
    "for i in tqdm(range(len(random_images)), desc=\"Processing random images\"):\n",
    "    image = preprocess(random_images[i]).unsqueeze(0).to(device)\n",
    "\n",
    "    hook_manager.reinit()\n",
    "    hook_manager.intervene_register_neurons(\n",
    "        neurons_to_ablate=neurons_to_ablate,\n",
    "        num_registers=num_registers,\n",
    "        normal_values=\"zero\",\n",
    "        scale=1,\n",
    "    )\n",
    "    hook_manager.finalize()\n",
    "    representation = run_model(model, image, num_registers=num_registers)\n",
    "    attention_maps = hook_manager.get_attention_maps()\n",
    "    layer_outputs = hook_manager.get_layer_outputs()\n",
    "\n",
    "    layer_norms = np.linalg.norm(layer_outputs[detect_outliers_layer], axis=1)\n",
    "\n",
    "    image_patch_norms = layer_norms[1 : patch_height * patch_width + 1]\n",
    "    register_patch_norms = layer_norms[patch_height * patch_width + 1 :]\n",
    "\n",
    "    image_norms.extend(image_patch_norms.tolist())\n",
    "    register_norms.extend(register_patch_norms.tolist())\n",
    "\n",
    "    image_attentions.append(\n",
    "        np.max(attention_maps[-1, :, 0, 1 : patch_height * patch_width + 1])\n",
    "    )\n",
    "    register_attentions.append(\n",
    "        np.max(attention_maps[-1, :, 0, patch_height * patch_width + 1 :])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb9d10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:27:31.663643Z",
     "iopub.status.busy": "2025-11-21T16:27:31.663328Z",
     "iopub.status.idle": "2025-11-21T16:27:38.674439Z",
     "shell.execute_reply": "2025-11-21T16:27:38.673635Z"
    },
    "papermill": {
     "duration": 7.048935,
     "end_time": "2025-11-21T16:27:38.675750",
     "exception": false,
     "start_time": "2025-11-21T16:27:31.626815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process images with register intervention\n",
    "random_images = load_images(IMAGE_PATH, count=50)\n",
    "image_norms = []\n",
    "register_norms = []\n",
    "image_attentions = []\n",
    "register_attentions = []\n",
    "\n",
    "for i in tqdm(range(len(random_images)), desc=\"Processing random images\"):\n",
    "    image = preprocess(random_images[i]).unsqueeze(0).to(device)\n",
    "    hook_manager.reinit()\n",
    "    hook_manager.intervene_register_neurons(\n",
    "        neurons_to_ablate=neurons_to_ablate,\n",
    "        num_registers=num_registers,\n",
    "        normal_values=\"zero\",\n",
    "        scale=1,\n",
    "    )\n",
    "    hook_manager.finalize()\n",
    "    representation = run_model(model, image, num_registers=num_registers)\n",
    "    attention_maps = hook_manager.get_attention_maps()\n",
    "    layer_outputs = hook_manager.get_layer_outputs()\n",
    "\n",
    "    layer_norms = np.linalg.norm(layer_outputs[detect_outliers_layer], axis=1)\n",
    "    image_patch_norms = layer_norms[1 : patch_height * patch_width + 1]\n",
    "    register_patch_norms = layer_norms[patch_height * patch_width + 1 :]\n",
    "\n",
    "    image_norms.extend(image_patch_norms.tolist())\n",
    "    register_norms.extend(register_patch_norms.tolist())\n",
    "    image_attentions.append(\n",
    "        np.max(attention_maps[-1, :, 0, 1 : patch_height * patch_width + 1])\n",
    "    )\n",
    "    register_attentions.append(\n",
    "        np.max(attention_maps[-1, :, 0, patch_height * patch_width + 1 :])\n",
    "    )\n",
    "\n",
    "# Now compute layer-wise statistics across all images\n",
    "max_patch_norms = [0] * num_layers\n",
    "max_attn_norms = [0] * num_layers\n",
    "\n",
    "for image in tqdm(random_images, desc=\"Computing layer-wise statistics\"):\n",
    "    processed_image = preprocess(image).unsqueeze(0).to(device)\n",
    "    hook_manager.reinit()\n",
    "    hook_manager.intervene_register_neurons(\n",
    "        neurons_to_ablate=neurons_to_ablate,\n",
    "        num_registers=num_registers,\n",
    "        normal_values=\"zero\",\n",
    "        scale=1,\n",
    "    )\n",
    "    hook_manager.finalize()\n",
    "    representation = run_model(model, processed_image, num_registers=num_registers)\n",
    "    attention_maps = hook_manager.get_attention_maps()  # shape (L, H, N, N)\n",
    "    layer_outputs = hook_manager.get_layer_outputs()  # shape (L, N, D)\n",
    "\n",
    "    # Compute max patch norms per layer\n",
    "    patch_norms = np.max(\n",
    "        np.linalg.norm(layer_outputs[:, 1 : patch_height * patch_width + 1], axis=2),\n",
    "        axis=1,\n",
    "    )\n",
    "    # Compute max attention to image patches from CLS token per layer\n",
    "    attn_norms = np.max(\n",
    "        np.mean(attention_maps[:, :, 0, 1 : patch_height * patch_width + 1], axis=1),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    for j in range(num_layers):\n",
    "        max_attn_norms[j] += attn_norms[j]\n",
    "        max_patch_norms[j] += patch_norms[j]\n",
    "\n",
    "# Average over all images\n",
    "max_attn_norms = [x / len(random_images) for x in max_attn_norms]\n",
    "max_patch_norms = [x / len(random_images) for x in max_patch_norms]\n",
    "\n",
    "# Create the visualization\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 5), dpi=100)\n",
    "\n",
    "# === Subplot 1: Patch Norms ===\n",
    "ax1.plot(\n",
    "    range(num_layers),\n",
    "    max_patch_norms,\n",
    "    marker=\"o\",\n",
    "    markersize=8,\n",
    "    color=\"steelblue\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax1.set_title(\"Average Max Patch Norms (Layer output) - With Register Ablation\")\n",
    "ax1.set_xlabel(\"Layer\")\n",
    "ax1.set_ylabel(\"Norm\")\n",
    "ax1.set_xticks(range(0, num_layers, 2))\n",
    "ax1.tick_params(axis=\"both\")\n",
    "ax1.tick_params(axis=\"x\", which=\"major\", pad=15)\n",
    "ax1.margins(x=0.1)\n",
    "ax1.grid(True, linestyle=\"-\")\n",
    "\n",
    "# === Subplot 2: Attention Norms ===\n",
    "ax2.plot(\n",
    "    range(num_layers),\n",
    "    max_attn_norms,\n",
    "    marker=\"^\",\n",
    "    markersize=8,\n",
    "    color=\"orange\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax2.set_title(\"Average Max Attention (CLS) - With Register Ablation\")\n",
    "ax2.set_xlabel(\"Layer\")\n",
    "ax2.set_ylabel(\"Attention Value\")\n",
    "ax2.set_xticks(range(0, num_layers, 2))\n",
    "ax2.tick_params(axis=\"both\")\n",
    "ax2.tick_params(axis=\"x\", which=\"major\", pad=15)\n",
    "ax2.margins(x=0.1)\n",
    "ax2.grid(True, linestyle=\"-\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d602f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:27:38.756138Z",
     "iopub.status.busy": "2025-11-21T16:27:38.755840Z",
     "iopub.status.idle": "2025-11-21T16:27:39.748964Z",
     "shell.execute_reply": "2025-11-21T16:27:39.748289Z"
    },
    "papermill": {
     "duration": 1.034645,
     "end_time": "2025-11-21T16:27:39.750976",
     "exception": false,
     "start_time": "2025-11-21T16:27:38.716331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the image norms and register norms as histograms side by side\n",
    "plt.figure(figsize=(10, 12))\n",
    "\n",
    "# Plot image norms\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(image_norms, bins=50, alpha=0.7, color=\"blue\")\n",
    "plt.xlabel(\"Norm Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Image Patch Norms\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axvline(\n",
    "    x=np.median(image_norms),\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Median: {np.median(image_norms):.2f}\",\n",
    ")\n",
    "plt.legend()\n",
    "\n",
    "# Plot register norms\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(register_norms, bins=50, alpha=0.7, color=\"green\")\n",
    "plt.xlabel(\"Norm Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Register Patch Norms\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axvline(\n",
    "    x=np.median(register_norms),\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Median: {np.median(register_norms):.2f}\",\n",
    ")\n",
    "plt.legend()\n",
    "\n",
    "# Plot image attentions\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(image_attentions, bins=50, alpha=0.7, color=\"blue\")\n",
    "plt.xlabel(\"Attention Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Image Patch Attentions\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axvline(\n",
    "    x=np.median(image_attentions),\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Median: {np.median(image_attentions):.2f}\",\n",
    ")\n",
    "plt.legend()\n",
    "\n",
    "# Plot register attentions\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(register_attentions, bins=50, alpha=0.7, color=\"green\")\n",
    "plt.xlabel(\"Attention Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Register Patch Attentions\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axvline(\n",
    "    x=np.median(register_attentions),\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Median: {np.median(register_attentions):.2f}\",\n",
    ")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics for comparison\n",
    "print(\n",
    "    f\"Image norms - Min: {min(image_norms):.2f}, Max: {max(image_norms):.2f}, Mean: {np.mean(image_norms):.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Register norms - Min: {min(register_norms):.2f}, Max: {max(register_norms):.2f}, Mean: {np.mean(register_norms):.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Image attentions - Min: {min(image_attentions):.2f}, Max: {max(image_attentions):.2f}, Mean: {np.mean(image_attentions):.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Register attentions - Min: {min(register_attentions):.2f}, Max: {max(register_attentions):.2f}, Mean: {np.mean(register_attentions):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac59385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:27:39.831349Z",
     "iopub.status.busy": "2025-11-21T16:27:39.830887Z",
     "iopub.status.idle": "2025-11-21T16:27:39.886928Z",
     "shell.execute_reply": "2025-11-21T16:27:39.886206Z"
    },
    "papermill": {
     "duration": 0.096668,
     "end_time": "2025-11-21T16:27:39.888068",
     "exception": false,
     "start_time": "2025-11-21T16:27:39.791400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = load_images(IMAGE_PATH, count=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfabbb5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:27:39.967938Z",
     "iopub.status.busy": "2025-11-21T16:27:39.967386Z",
     "iopub.status.idle": "2025-11-21T16:27:40.090152Z",
     "shell.execute_reply": "2025-11-21T16:27:40.089391Z"
    },
    "papermill": {
     "duration": 0.163576,
     "end_time": "2025-11-21T16:27:40.091306",
     "exception": false,
     "start_time": "2025-11-21T16:27:39.927730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Input\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37566090",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:27:40.174116Z",
     "iopub.status.busy": "2025-11-21T16:27:40.173402Z",
     "iopub.status.idle": "2025-11-21T16:27:40.323306Z",
     "shell.execute_reply": "2025-11-21T16:27:40.322486Z"
    },
    "papermill": {
     "duration": 0.192268,
     "end_time": "2025-11-21T16:27:40.324874",
     "exception": false,
     "start_time": "2025-11-21T16:27:40.132606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_image = preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "hook_manager.reinit()\n",
    "hook_manager.finalize()\n",
    "representation = run_model(model, processed_image)\n",
    "original_attention_maps = hook_manager.get_attention_maps()\n",
    "original_layer_outputs = hook_manager.get_layer_outputs()\n",
    "\n",
    "hook_manager.reinit()\n",
    "hook_manager.intervene_register_neurons(\n",
    "    neurons_to_ablate=neurons_to_ablate, num_registers=num_registers\n",
    ")\n",
    "hook_manager.finalize()\n",
    "representation = run_model(model, processed_image, num_registers=num_registers)\n",
    "ablated_attention_maps = hook_manager.get_attention_maps()\n",
    "ablated_layer_outputs = hook_manager.get_layer_outputs()\n",
    "ablated_neuron_activations = hook_manager.get_neuron_activations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01f89a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:27:40.405412Z",
     "iopub.status.busy": "2025-11-21T16:27:40.405121Z",
     "iopub.status.idle": "2025-11-21T16:27:45.999529Z",
     "shell.execute_reply": "2025-11-21T16:27:45.998817Z"
    },
    "papermill": {
     "duration": 5.642216,
     "end_time": "2025-11-21T16:27:46.006730",
     "exception": false,
     "start_time": "2025-11-21T16:27:40.364514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Norm map of output patch embeddings - baseline and ablated comparison for all layers\n",
    "\n",
    "# Import the necessary module for make_axes_locatable\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# Create a figure with subplots for each layer (1 row per layer)\n",
    "fig, axs = plt.subplots(num_layers, 2, figsize=(16, 4 * num_layers))\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.3)\n",
    "\n",
    "# Plot norm maps for each layer\n",
    "for layer in range(num_layers):\n",
    "    # Calculate norms for baseline and ablated outputs\n",
    "\n",
    "    # Calculate norms for outputs\n",
    "    baseline_output_norms_flat = np.linalg.norm(\n",
    "        original_layer_outputs[layer, 1:], axis=1\n",
    "    )\n",
    "    ablated_output_norms_flat = np.linalg.norm(ablated_layer_outputs[layer, 1:], axis=1)\n",
    "\n",
    "    # Handle non-square reshaping\n",
    "    def reshape_with_extras(flat_array, patch_height, patch_width):\n",
    "        total_patches = len(flat_array)\n",
    "        if total_patches == patch_height * patch_width:\n",
    "            # Perfect square case\n",
    "            return flat_array.reshape((patch_height, patch_width)), None\n",
    "        else:\n",
    "            # Non-square case\n",
    "            square_part = flat_array[: patch_height * patch_width].reshape(\n",
    "                (patch_height, patch_width)\n",
    "            )\n",
    "            extra_part = flat_array[patch_height * patch_width :]\n",
    "            return square_part, extra_part\n",
    "\n",
    "    # Reshape with handling for extra values\n",
    "    baseline_output_norms, baseline_output_extras = reshape_with_extras(\n",
    "        baseline_output_norms_flat, patch_height, patch_width\n",
    "    )\n",
    "    ablated_output_norms, ablated_output_extras = reshape_with_extras(\n",
    "        ablated_output_norms_flat, patch_height, patch_width\n",
    "    )\n",
    "\n",
    "    # Plot baseline output\n",
    "    im3 = axs[layer, 0].imshow(baseline_output_norms, cmap=\"viridis\")\n",
    "    extra_info = \"\"\n",
    "    axs[layer, 0].set_title(\n",
    "        f\"Layer {layer} - Original (output){extra_info}\", fontsize=14\n",
    "    )\n",
    "    axs[layer, 0].set_xlabel(\"Patch X\", fontsize=12)\n",
    "    axs[layer, 0].set_ylabel(\"Patch Y\", fontsize=12)\n",
    "\n",
    "    # Add colorbar for output original\n",
    "    divider = make_axes_locatable(axs[layer, 0])\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar = fig.colorbar(im3, cax=cax)\n",
    "    cbar.set_label(f\"Layer {layer} Output Norm\", fontsize=12)\n",
    "\n",
    "    # Plot ablated output\n",
    "    im4 = axs[layer, 1].imshow(ablated_output_norms, cmap=\"viridis\")\n",
    "    extra_info = \"\"\n",
    "    axs[layer, 1].set_title(\n",
    "        f\"Layer {layer} - Ablated (output){extra_info}\", fontsize=14\n",
    "    )\n",
    "    axs[layer, 1].set_xlabel(\"Patch X\", fontsize=12)\n",
    "    axs[layer, 1].set_ylabel(\"Patch Y\", fontsize=12)\n",
    "\n",
    "    # Add colorbar for output ablated\n",
    "    divider = make_axes_locatable(axs[layer, 1])\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar = fig.colorbar(im4, cax=cax)\n",
    "    cbar.set_label(f\"Layer {layer} Output Norm\", fontsize=12)\n",
    "\n",
    "fig.suptitle(\"Norm Maps of Image Patches Across All Layers\", fontsize=20, y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4fcd9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:27:46.104116Z",
     "iopub.status.busy": "2025-11-21T16:27:46.103864Z",
     "iopub.status.idle": "2025-11-21T16:27:51.551498Z",
     "shell.execute_reply": "2025-11-21T16:27:51.550526Z"
    },
    "papermill": {
     "duration": 5.501166,
     "end_time": "2025-11-21T16:27:51.556767",
     "exception": false,
     "start_time": "2025-11-21T16:27:46.055601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Original attention maps\n",
    "plt = plot_attn_maps(\n",
    "    original_attention_maps[:, :, 0, 1 : patch_height * patch_width + 1].reshape(\n",
    "        (num_layers, num_heads, patch_height, patch_width)\n",
    "    )\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948364db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:27:51.765922Z",
     "iopub.status.busy": "2025-11-21T16:27:51.765410Z",
     "iopub.status.idle": "2025-11-21T16:27:57.660134Z",
     "shell.execute_reply": "2025-11-21T16:27:57.659303Z"
    },
    "papermill": {
     "duration": 6.036542,
     "end_time": "2025-11-21T16:27:57.664344",
     "exception": false,
     "start_time": "2025-11-21T16:27:51.627802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ablated attention maps\n",
    "plt = plot_attn_maps(\n",
    "    ablated_attention_maps[:, :, 0, 1 : patch_height * patch_width + 1].reshape(\n",
    "        (num_layers, num_heads, patch_height, patch_width)\n",
    "    )\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5610a07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:27:57.778380Z",
     "iopub.status.busy": "2025-11-21T16:27:57.777759Z",
     "iopub.status.idle": "2025-11-21T16:27:57.788706Z",
     "shell.execute_reply": "2025-11-21T16:27:57.788149Z"
    },
    "papermill": {
     "duration": 0.068277,
     "end_time": "2025-11-21T16:27:57.789788",
     "exception": false,
     "start_time": "2025-11-21T16:27:57.721511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class OrthoNetDataset(Dataset):\n",
    "#     def __init__(self, dataframe, img_dir, class_to_idx, model, ttr=False):\n",
    "#         self.dataframe = dataframe.reset_index(drop=True)\n",
    "#         self.img_dir = img_dir\n",
    "#         self.class_to_idx = class_to_idx\n",
    "#         # Remove this line - transform is not defined\n",
    "#         # self.transform = transform\n",
    "#         self.model = model\n",
    "#         self.device = device\n",
    "#         self.ttr = ttr\n",
    "        \n",
    "#         # Set model to eval mode\n",
    "#         self.model.eval()\n",
    "#         self.model.to(device)\n",
    "        \n",
    "#         self.representations = []\n",
    "#         self.labels = []\n",
    "        \n",
    "#         with torch.no_grad():  # Add this for efficiency and to prevent gradient tracking\n",
    "#             for _, row in tqdm(self.dataframe.iterrows(), \n",
    "#                               total=len(self.dataframe), \n",
    "#                               desc=\"Processing images\"):\n",
    "#                 img_path = os.path.join(self.img_dir, row[\"filenames\"])\n",
    "#                 img = Image.open(img_path).convert(\"RGB\")\n",
    "#                 processed_image = preprocess(img).unsqueeze(0).to(device)\n",
    "                \n",
    "#                 hook_manager.reinit()\n",
    "#                 if ttr:\n",
    "#                     hook_manager.intervene_register_neurons(\n",
    "#                         neurons_to_ablate=neurons_to_ablate,\n",
    "#                         num_registers=num_registers,\n",
    "#                         normal_values=\"zero\",\n",
    "#                         scale=1,\n",
    "#                     )\n",
    "#                 hook_manager.finalize()\n",
    "                \n",
    "#                 # Fixed: run_model should take (model, image, num_registers)\n",
    "#                 representation = run_model(model, processed_image, num_registers=num_registers)\n",
    "#                 representation = representation.squeeze(0).cpu()\n",
    "                \n",
    "#                 self.representations.append(representation)\n",
    "#                 self.labels.append(self.class_to_idx[row[\"labels\"]])\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.dataframe)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         representation = self.representations[idx]\n",
    "#         label = self.labels[idx]\n",
    "        \n",
    "#         return representation, label\n",
    "\n",
    "\n",
    "class PacemakerDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, class_to_idx, model, ttr=False):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.ttr = ttr\n",
    "        \n",
    "        # Set model to eval mode\n",
    "        self.model.eval()\n",
    "        self.model.to(device)\n",
    "        \n",
    "        self.representations = []\n",
    "        self.labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _, row in tqdm(self.dataframe.iterrows(), \n",
    "                              total=len(self.dataframe), \n",
    "                              desc=\"Processing images\"):\n",
    "                # For Pacemaker: img_path includes split (train/test) + class folder + filename\n",
    "                img_path = os.path.join(self.img_dir, row[\"split\"], row[\"class_folder\"], row[\"filename\"])\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                processed_image = preprocess(img).unsqueeze(0).to(device)\n",
    "                \n",
    "                hook_manager.reinit()\n",
    "                if ttr:\n",
    "                    hook_manager.intervene_register_neurons(\n",
    "                        neurons_to_ablate=neurons_to_ablate,\n",
    "                        num_registers=num_registers,\n",
    "                        normal_values=\"zero\",\n",
    "                        scale=1,\n",
    "                    )\n",
    "                hook_manager.finalize()\n",
    "                \n",
    "                representation = run_model(model, processed_image, num_registers=num_registers)\n",
    "                representation = representation.squeeze(0).cpu()\n",
    "                \n",
    "                self.representations.append(representation)\n",
    "                self.labels.append(self.class_to_idx[row[\"labels\"]])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        representation = self.representations[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return representation, label\n",
    "        \n",
    "def create_pacemaker_dataframe(pacemaker_path, split='train'):\n",
    "    \"\"\"\n",
    "    Create a dataframe for Pacemaker dataset similar to OrthoNet's structure.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame with columns: ['filename', 'class_folder', 'labels', 'split']\n",
    "    \"\"\"\n",
    "    split_path = os.path.join(pacemaker_path, split)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # Get all class folders\n",
    "    all_classes = sorted([d for d in os.listdir(split_path) \n",
    "                         if os.path.isdir(os.path.join(split_path, d))])\n",
    "    \n",
    "    for class_name in all_classes:\n",
    "        class_path = os.path.join(split_path, class_name)\n",
    "        \n",
    "        # Get all image files\n",
    "        image_files = [f for f in os.listdir(class_path) \n",
    "                      if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
    "        \n",
    "        for img_file in image_files:\n",
    "            data.append({\n",
    "                'filename': img_file,\n",
    "                'class_folder': class_name,\n",
    "                'labels': class_name,\n",
    "                'split': split  # Add split information\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"{split} set: {len(df)} images across {len(all_classes)} classes\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9adb046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:27:57.898508Z",
     "iopub.status.busy": "2025-11-21T16:27:57.898228Z",
     "iopub.status.idle": "2025-11-21T16:27:58.316411Z",
     "shell.execute_reply": "2025-11-21T16:27:58.315419Z"
    },
    "papermill": {
     "duration": 0.474603,
     "end_time": "2025-11-21T16:27:58.317731",
     "exception": false,
     "start_time": "2025-11-21T16:27:57.843128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create dataframes\n",
    "PACEMAKER_PATH = '/kaggle/input/pacemakers'\n",
    "\n",
    "# Load train and test\n",
    "train_full_df = create_pacemaker_dataframe(PACEMAKER_PATH, split='Train')\n",
    "test_df = create_pacemaker_dataframe(PACEMAKER_PATH, split='Test')\n",
    "\n",
    "# Split train into train and val (e.g., 80-20 or 90-10 split)\n",
    "# Stratify by class to maintain class distribution\n",
    "train_df, val_df = train_test_split(\n",
    "    train_full_df, \n",
    "    test_size=0.2,  # 20% for validation, adjust as needed\n",
    "    stratify=train_full_df['labels'],  # Maintain class balance\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal splits:\")\n",
    "print(f\"Train: {len(train_df)} images\")\n",
    "print(f\"Val: {len(val_df)} images\")\n",
    "print(f\"Test: {len(test_df)} images\")\n",
    "\n",
    "# Create class_to_idx mapping from all classes in train\n",
    "all_classes = sorted(train_full_df['labels'].unique())\n",
    "class_to_idx = {class_name: idx for idx, class_name in enumerate(all_classes)}\n",
    "print(f\"\\nNumber of classes: {len(class_to_idx)}\")\n",
    "\n",
    "# img_dir should point to the pacemaker root\n",
    "img_dir = PACEMAKER_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df8e49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:27:58.425813Z",
     "iopub.status.busy": "2025-11-21T16:27:58.425532Z",
     "iopub.status.idle": "2025-11-21T16:27:58.429987Z",
     "shell.execute_reply": "2025-11-21T16:27:58.429406Z"
    },
    "papermill": {
     "duration": 0.059794,
     "end_time": "2025-11-21T16:27:58.431169",
     "exception": false,
     "start_time": "2025-11-21T16:27:58.371375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(neurons_to_ablate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9036bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:27:58.540637Z",
     "iopub.status.busy": "2025-11-21T16:27:58.540337Z",
     "iopub.status.idle": "2025-11-21T16:32:41.267640Z",
     "shell.execute_reply": "2025-11-21T16:32:41.266814Z"
    },
    "papermill": {
     "duration": 282.784557,
     "end_time": "2025-11-21T16:32:41.268803",
     "exception": false,
     "start_time": "2025-11-21T16:27:58.484246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset_no_ttr = PacemakerDataset(\n",
    "    train_df, img_dir, class_to_idx, model, ttr=False\n",
    ")\n",
    "val_dataset_no_ttr = PacemakerDataset(\n",
    "    val_df, img_dir, class_to_idx, model, ttr=False\n",
    ")\n",
    "test_dataset_no_ttr = PacemakerDataset(\n",
    "    test_df, img_dir, class_to_idx, model, ttr=False\n",
    ")\n",
    "train_dataset_ttr = PacemakerDataset(\n",
    "    train_df, img_dir, class_to_idx, model, ttr=True\n",
    ")\n",
    "val_dataset_ttr = PacemakerDataset(\n",
    "    val_df, img_dir, class_to_idx, model, ttr=True\n",
    ")\n",
    "test_dataset_ttr = PacemakerDataset(\n",
    "    test_df, img_dir, class_to_idx, model, ttr=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d6cf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:32:41.571495Z",
     "iopub.status.busy": "2025-11-21T16:32:41.570957Z",
     "iopub.status.idle": "2025-11-21T16:32:41.578242Z",
     "shell.execute_reply": "2025-11-21T16:32:41.577252Z"
    },
    "papermill": {
     "duration": 0.161137,
     "end_time": "2025-11-21T16:32:41.579550",
     "exception": false,
     "start_time": "2025-11-21T16:32:41.418413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader_no_ttr = DataLoader(train_dataset_no_ttr, batch_size=32, shuffle=True, num_workers=4)\n",
    "train_loader_ttr = DataLoader(train_dataset_ttr, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader_no_ttr = DataLoader(val_dataset_no_ttr, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader_ttr = DataLoader(val_dataset_ttr, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader_no_ttr = DataLoader(test_dataset_no_ttr, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader_ttr = DataLoader(test_dataset_ttr, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "num_classes = 45\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fb2a17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:32:41.853327Z",
     "iopub.status.busy": "2025-11-21T16:32:41.852633Z",
     "iopub.status.idle": "2025-11-21T16:32:41.857143Z",
     "shell.execute_reply": "2025-11-21T16:32:41.856613Z"
    },
    "papermill": {
     "duration": 0.136815,
     "end_time": "2025-11-21T16:32:41.858150",
     "exception": false,
     "start_time": "2025-11-21T16:32:41.721335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=512, num_classes=10):\n",
    "        print(input_dim)\n",
    "        print(num_classes)\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298a54d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:32:42.124157Z",
     "iopub.status.busy": "2025-11-21T16:32:42.123260Z",
     "iopub.status.idle": "2025-11-21T16:32:42.129700Z",
     "shell.execute_reply": "2025-11-21T16:32:42.129066Z"
    },
    "papermill": {
     "duration": 0.142738,
     "end_time": "2025-11-21T16:32:42.130746",
     "exception": false,
     "start_time": "2025-11-21T16:32:41.988008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, y_prob):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    metrics = {}\n",
    "    metrics[\"accuracy\"] = (y_true == y_pred).mean()\n",
    "\n",
    "    top3 = np.argsort(-y_prob, axis=1)[:, :3]\n",
    "    top3_acc = np.mean([y_true[i] in top3[i] for i in range(len(y_true))])\n",
    "    metrics[\"top3_accuracy\"] = top3_acc\n",
    "\n",
    "    metrics[\"f1\"] = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    metrics[\"precision\"] = precision_score(\n",
    "        y_true, y_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    metrics[\"recall\"] = recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    try:\n",
    "        metrics[\"auc_roc\"] = roc_auc_score(y_true, y_prob, multi_class=\"ovr\")\n",
    "    except:\n",
    "        metrics[\"auc_roc\"] = None\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bae995f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:32:42.404195Z",
     "iopub.status.busy": "2025-11-21T16:32:42.403917Z",
     "iopub.status.idle": "2025-11-21T16:32:42.414922Z",
     "shell.execute_reply": "2025-11-21T16:32:42.414167Z"
    },
    "papermill": {
     "duration": 0.146501,
     "end_time": "2025-11-21T16:32:42.416082",
     "exception": false,
     "start_time": "2025-11-21T16:32:42.269581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, train_loader, val_loader, criterion, optimizer, scheduler, method, epochs\n",
    "):\n",
    "    train_history, val_history = [], []\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_acc = 0\n",
    "    best_model_path = \"best_model_\" + method + \".pth\"\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        all_labels, all_preds, all_probs = [], [], []\n",
    "\n",
    "        for images, labels in tqdm(\n",
    "            train_loader, desc=f\"Train Epoch {epoch+1}/{epochs}\"\n",
    "        ):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            probs = torch.softmax(outputs, dim=1).detach().cpu().numpy()\n",
    "            preds = outputs.argmax(dim=1).detach().cpu().numpy()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds)\n",
    "            all_probs.extend(probs)\n",
    "\n",
    "        scheduler.step()\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_metrics = compute_metrics(all_labels, all_preds, np.array(all_probs))\n",
    "        train_metrics[\"loss\"] = avg_train_loss\n",
    "        train_history.append(train_metrics)\n",
    "\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        all_labels, all_preds, all_probs = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "                preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(preds)\n",
    "                all_probs.extend(probs)\n",
    "\n",
    "        avg_val_loss = total_loss / len(val_loader)\n",
    "        val_metrics = compute_metrics(all_labels, all_preds, np.array(all_probs))\n",
    "        val_metrics[\"loss\"] = avg_val_loss\n",
    "        val_history.append(val_metrics)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}: \"\n",
    "            f\"Train Loss={avg_train_loss:.4f}, Train Acc={train_metrics['accuracy']:.4f} | \"\n",
    "            f\"Val Loss={avg_val_loss:.4f}, Val Acc={val_metrics['accuracy']:.4f}\"\n",
    "        )\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_val_acc = val_metrics[\"accuracy\"]\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(\n",
    "                f\"Best model saved at epoch {epoch+1} with Val Loss={avg_val_loss:.4f}\"\n",
    "            )\n",
    "\n",
    "    with open(\"train_metrics_\" + method + \".json\", \"w\") as f:\n",
    "        json.dump(train_history, f, indent=4)\n",
    "    with open(\"val_metrics_\" + method + \".json\", \"w\") as f:\n",
    "        json.dump(val_history, f, indent=4)\n",
    "\n",
    "    print(f\"\\nBest Validation Accuracy: {best_val_acc:.4f}\")\n",
    "    return train_history, val_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc8f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:32:42.683044Z",
     "iopub.status.busy": "2025-11-21T16:32:42.682766Z",
     "iopub.status.idle": "2025-11-21T16:32:42.688429Z",
     "shell.execute_reply": "2025-11-21T16:32:42.687834Z"
    },
    "papermill": {
     "duration": 0.141905,
     "end_time": "2025-11-21T16:32:42.689606",
     "exception": false,
     "start_time": "2025-11-21T16:32:42.547701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    all_labels, all_preds, all_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds)\n",
    "            all_probs.extend(probs)\n",
    "\n",
    "    metrics = compute_metrics(all_labels, all_preds, np.array(all_probs))\n",
    "\n",
    "    print(f\"Test Acc ={metrics['accuracy']:.4f}\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f00019b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:32:42.964597Z",
     "iopub.status.busy": "2025-11-21T16:32:42.963719Z",
     "iopub.status.idle": "2025-11-21T16:32:42.968765Z",
     "shell.execute_reply": "2025-11-21T16:32:42.968206Z"
    },
    "papermill": {
     "duration": 0.143581,
     "end_time": "2025-11-21T16:32:42.969795",
     "exception": false,
     "start_time": "2025-11-21T16:32:42.826214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_metrics(train_history, test_history, metric=\"accuracy\"):\n",
    "    train_vals = [m[metric] for m in train_history]\n",
    "    test_vals = [m[metric] for m in test_history]\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(train_vals, label=f\"Train {metric}\")\n",
    "    plt.plot(test_vals, label=f\"Validation {metric}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.title(f\"{metric.capitalize()} over epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85245939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:32:43.234016Z",
     "iopub.status.busy": "2025-11-21T16:32:43.233685Z",
     "iopub.status.idle": "2025-11-21T16:32:43.238306Z",
     "shell.execute_reply": "2025-11-21T16:32:43.237582Z"
    },
    "papermill": {
     "duration": 0.139222,
     "end_time": "2025-11-21T16:32:43.239621",
     "exception": false,
     "start_time": "2025-11-21T16:32:43.100399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa889ad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:32:43.510570Z",
     "iopub.status.busy": "2025-11-21T16:32:43.509617Z",
     "iopub.status.idle": "2025-11-21T16:32:43.515575Z",
     "shell.execute_reply": "2025-11-21T16:32:43.514705Z"
    },
    "papermill": {
     "duration": 0.144811,
     "end_time": "2025-11-21T16:32:43.516836",
     "exception": false,
     "start_time": "2025-11-21T16:32:43.372025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Usage example:\n",
    "classifier = LinearClassifier(input_dim=512, num_classes=num_classes)\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473133a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:32:43.865108Z",
     "iopub.status.busy": "2025-11-21T16:32:43.863397Z",
     "iopub.status.idle": "2025-11-21T16:33:13.968975Z",
     "shell.execute_reply": "2025-11-21T16:33:13.968023Z"
    },
    "papermill": {
     "duration": 30.4742,
     "end_time": "2025-11-21T16:33:14.120819",
     "exception": false,
     "start_time": "2025-11-21T16:32:43.646619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(classifier.parameters(), lr=1e-3, weight_decay=0.05)\n",
    "epochs = 50\n",
    "\n",
    "T_max = epochs\n",
    "eta_min = 1e-5\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=T_max, eta_min=eta_min\n",
    ")\n",
    "\n",
    "method = \"no_ttr\"\n",
    "train_history, val_history = train(\n",
    "    classifier,\n",
    "    train_loader_no_ttr,\n",
    "    val_loader_no_ttr,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    method,\n",
    "    epochs,\n",
    ")\n",
    "\n",
    "plot_metrics(train_history, val_history, metric=\"loss\")\n",
    "plot_metrics(train_history, val_history, metric=\"accuracy\")\n",
    "plot_metrics(train_history, val_history, metric=\"top3_accuracy\")\n",
    "plot_metrics(train_history, val_history, metric=\"f1\")\n",
    "plot_metrics(train_history, val_history, metric=\"precision\")\n",
    "plot_metrics(train_history, val_history, metric=\"recall\")\n",
    "plot_metrics(train_history, val_history, metric=\"auc_roc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c548d3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:33:14.415930Z",
     "iopub.status.busy": "2025-11-21T16:33:14.415653Z",
     "iopub.status.idle": "2025-11-21T16:33:14.650471Z",
     "shell.execute_reply": "2025-11-21T16:33:14.649592Z"
    },
    "papermill": {
     "duration": 0.385373,
     "end_time": "2025-11-21T16:33:14.651671",
     "exception": false,
     "start_time": "2025-11-21T16:33:14.266298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "method = \"no_ttr\"\n",
    "classifier.load_state_dict(torch.load(\"best_model_\" + method + \".pth\"))\n",
    "\n",
    "test_metrics = test(classifier, test_loader_no_ttr)\n",
    "with open(\"test_metrics_\" + method + \".json\", \"w\") as f:\n",
    "    json.dump(test_metrics, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ae0f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:33:14.947328Z",
     "iopub.status.busy": "2025-11-21T16:33:14.947027Z",
     "iopub.status.idle": "2025-11-21T16:33:14.953397Z",
     "shell.execute_reply": "2025-11-21T16:33:14.952487Z"
    },
    "papermill": {
     "duration": 0.156855,
     "end_time": "2025-11-21T16:33:14.954846",
     "exception": false,
     "start_time": "2025-11-21T16:33:14.797991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier = LinearClassifier(input_dim=512, num_classes=num_classes)\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e173ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:33:15.279329Z",
     "iopub.status.busy": "2025-11-21T16:33:15.279049Z",
     "iopub.status.idle": "2025-11-21T16:33:44.666467Z",
     "shell.execute_reply": "2025-11-21T16:33:44.665600Z"
    },
    "papermill": {
     "duration": 29.549523,
     "end_time": "2025-11-21T16:33:44.667783",
     "exception": false,
     "start_time": "2025-11-21T16:33:15.118260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(classifier.parameters(), lr=1e-3, weight_decay=0.05)\n",
    "epochs = 50\n",
    "\n",
    "T_max = epochs\n",
    "eta_min = 1e-5\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=T_max, eta_min=eta_min\n",
    ")\n",
    "\n",
    "method = \"ttr\"\n",
    "train_history, val_history = train(\n",
    "    classifier,\n",
    "    train_loader_ttr,\n",
    "    val_loader_ttr,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    method,\n",
    "    epochs,\n",
    ")\n",
    "\n",
    "plot_metrics(train_history, val_history, metric=\"loss\")\n",
    "plot_metrics(train_history, val_history, metric=\"accuracy\")\n",
    "plot_metrics(train_history, val_history, metric=\"top3_accuracy\")\n",
    "plot_metrics(train_history, val_history, metric=\"f1\")\n",
    "plot_metrics(train_history, val_history, metric=\"precision\")\n",
    "plot_metrics(train_history, val_history, metric=\"recall\")\n",
    "plot_metrics(train_history, val_history, metric=\"auc_roc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd2ce0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T16:33:44.999030Z",
     "iopub.status.busy": "2025-11-21T16:33:44.998133Z",
     "iopub.status.idle": "2025-11-21T16:33:45.224981Z",
     "shell.execute_reply": "2025-11-21T16:33:45.224183Z"
    },
    "papermill": {
     "duration": 0.39024,
     "end_time": "2025-11-21T16:33:45.226171",
     "exception": false,
     "start_time": "2025-11-21T16:33:44.835931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "method = \"ttr\"\n",
    "classifier.load_state_dict(torch.load(\"best_model_\" + method + \".pth\"))\n",
    "\n",
    "test_metrics = test(classifier, test_loader_ttr)\n",
    "with open(\"test_metrics_\" + method + \".json\", \"w\") as f:\n",
    "    json.dump(test_metrics, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd25709",
   "metadata": {
    "papermill": {
     "duration": 0.162996,
     "end_time": "2025-11-21T16:33:45.548001",
     "exception": false,
     "start_time": "2025-11-21T16:33:45.385005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1715304,
     "sourceId": 2822650,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8243834,
     "sourceId": 13020545,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8737268,
     "sourceId": 13732491,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 479277,
     "sourceId": 896238,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 493.242522,
   "end_time": "2025-11-21T16:33:48.463280",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-21T16:25:35.220758",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0991fda651c845d5bcff9c1b8ac2ea77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0d3c88fb55b041909f263a94f2cf47e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9f3f3f4308514709aab8c4334fffcc69",
        "IPY_MODEL_aa4dc34fa3ab4dcc9b32ae243bfe6157",
        "IPY_MODEL_f0fae6631a884a618dbe76fd3241b0d1"
       ],
       "layout": "IPY_MODEL_359d96d8a8fb48a6bec7bf52edb7bc35",
       "tabbable": null,
       "tooltip": null
      }
     },
     "359d96d8a8fb48a6bec7bf52edb7bc35": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "450d48603d314110a43bdc5ac28f2c47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "540b8b69eb6148a191c99d12c54d64e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "542f67e943d54dc3bf6179c6cccc7519": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "67b9f237f80f4ff6abf5c0614253a5f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f3f3f4308514709aab8c4334fffcc69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_67b9f237f80f4ff6abf5c0614253a5f5",
       "placeholder": "",
       "style": "IPY_MODEL_450d48603d314110a43bdc5ac28f2c47",
       "tabbable": null,
       "tooltip": null,
       "value": "open_clip_pytorch_model.bin:100%"
      }
     },
     "aa4dc34fa3ab4dcc9b32ae243bfe6157": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_540b8b69eb6148a191c99d12c54d64e3",
       "max": 598529951,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0991fda651c845d5bcff9c1b8ac2ea77",
       "tabbable": null,
       "tooltip": null,
       "value": 598529951
      }
     },
     "b578c09552f34a6dad4d2cb7d547861f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f0fae6631a884a618dbe76fd3241b0d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b578c09552f34a6dad4d2cb7d547861f",
       "placeholder": "",
       "style": "IPY_MODEL_542f67e943d54dc3bf6179c6cccc7519",
       "tabbable": null,
       "tooltip": null,
       "value": "599M/599M[00:03&lt;00:00,308MB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
